{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas numpy matplotlib seaborn scipy requests-cache retry-requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54566ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== IMPORTS ========\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd91bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "=== Correlation with Target (Sales) ===\n",
      "Sales                            1.000000\n",
      "Sales per customer               0.996306\n",
      "Order Item Total                 0.996306\n",
      "Sales_lag_1                      0.937114\n",
      "Department Id                    0.901650\n",
      "Order Item Product Price         0.894086\n",
      "Product Price                    0.894086\n",
      "Product Category Id              0.871668\n",
      "Category Id                      0.871668\n",
      "Order Item Cardprod Id           0.869906\n",
      "Product Card Id                  0.869906\n",
      "Order Item Quantity              0.822369\n",
      "order_hour                       0.792463\n",
      "Order Item Discount              0.792436\n",
      "Order Item Discount Rate         0.704495\n",
      "shipping_hour                    0.694716\n",
      "Days for shipping (real)         0.680200\n",
      "Customer Id                      0.654647\n",
      "Order Customer Id                0.654647\n",
      "Sales_lag_7                      0.606214\n",
      "Days for shipment (scheduled)    0.542588\n",
      "Late_delivery_risk               0.528297\n",
      "Customer Zipcode                 0.395862\n",
      "shipping_dayofweek               0.313081\n",
      "order_month                      0.212270\n",
      "Order Id                         0.209399\n",
      "Order Item Id                    0.209386\n",
      "shipping_month                   0.201972\n",
      "order_week                       0.199956\n",
      "shipping_week                    0.194935\n",
      "Order Item Profit Ratio          0.180687\n",
      "shipping_weekend                 0.166413\n",
      "order_dayofweek                  0.154737\n",
      "Benefit per order                0.142538\n",
      "Order Profit Per Order           0.142538\n",
      "Sales_lag_30                     0.126513\n",
      "precip                           0.113815\n",
      "order_weekend                    0.082490\n",
      "year                             0.078333\n",
      "humidity                         0.052751\n",
      "cloudcover                       0.037945\n",
      "tempmin                          0.000221\n",
      "windspeed                       -0.000971\n",
      "snow                            -0.004850\n",
      "temp                            -0.006338\n",
      "tempmax                         -0.024937\n",
      "temp_lag_1                      -0.033747\n",
      "temp_lag_7                      -0.040719\n",
      "temp_lag_30                     -0.047096\n",
      "solarradiation                  -0.058922\n",
      "Product Status                        NaN\n",
      "is_rain                               NaN\n",
      "is_snow                               NaN\n",
      "is_freezingrain                       NaN\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "Dropping 16 highly correlated features (>0.9): {'order_month', 'tempmin', 'Order Item Id', 'Product Card Id', 'Order Item Total', 'Product Price', 'shipping_month', 'temp', 'Sales', 'Order Customer Id', 'Department Id', 'Order Profit Per Order', 'Product Category Id', 'shipping_week', 'Sales_lag_1', 'Order Item Cardprod Id'}\n",
      "\n",
      "Saved Step 1 feature-filtered dataset: ./final_datasets/Feature_Selected_Step1.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Correlation filtering for DataCo + Weather dataset (Train/Validation only).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "INPUT_FILE = \"./final_datasets/DataCo_Weather_Lagged.csv\"  # Dataset with lags\n",
    "OUTPUT_FILE = \"./final_datasets/Feature_Selected_Step1.csv\"\n",
    "TARGET = \"Sales\"\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Use only Train/Validation (2015â€“2016)\n",
    "df[\"date_only\"] = pd.to_datetime(df[\"date_only\"], errors='coerce')\n",
    "df_train = df[df[\"date_only\"].dt.year.isin([2015, 2016])].copy()\n",
    "\n",
    "# Select numeric features (exclude ID columns and date)\n",
    "numeric_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in [\"latitude\", \"longitude\"]]  # keep coords separate\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_train[numeric_cols].corr()\n",
    "\n",
    "# Report correlation with target\n",
    "print(\"\\n=== Correlation with Target (Sales) ===\")\n",
    "target_corr = corr_matrix[TARGET].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Drop highly correlated features (> 0.9)\n",
    "threshold = 0.9\n",
    "to_drop = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            to_drop.add(colname)\n",
    "\n",
    "print(f\"\\nDropping {len(to_drop)} highly correlated features (>0.9): {to_drop}\")\n",
    "\n",
    "# Keep the rest\n",
    "selected_cols = [col for col in numeric_cols if col not in to_drop]\n",
    "\n",
    "# Save filtered dataset (Train only)\n",
    "df_train[selected_cols + [\"latitude\", \"longitude\", \"date_only\"]].to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved Step 1 feature-filtered dataset: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a5bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "=== Correlation with Target (Sales) ===\n",
      "Sales                            1.000000\n",
      "Sales per customer               0.996306\n",
      "Order Item Total                 0.996306\n",
      "Sales_lag_1                      0.937114\n",
      "Department Id                    0.901650\n",
      "Order Item Product Price         0.894086\n",
      "Product Price                    0.894086\n",
      "Product Category Id              0.871668\n",
      "Category Id                      0.871668\n",
      "Order Item Cardprod Id           0.869906\n",
      "Product Card Id                  0.869906\n",
      "Order Item Quantity              0.822369\n",
      "order_hour                       0.792463\n",
      "Order Item Discount              0.792436\n",
      "Order Item Discount Rate         0.704495\n",
      "shipping_hour                    0.694716\n",
      "Days for shipping (real)         0.680200\n",
      "Customer Id                      0.654647\n",
      "Order Customer Id                0.654647\n",
      "Sales_lag_7                      0.606214\n",
      "Days for shipment (scheduled)    0.542588\n",
      "Late_delivery_risk               0.528297\n",
      "Customer Zipcode                 0.395862\n",
      "shipping_dayofweek               0.313081\n",
      "order_month                      0.212270\n",
      "Order Id                         0.209399\n",
      "Order Item Id                    0.209386\n",
      "shipping_month                   0.201972\n",
      "order_week                       0.199956\n",
      "shipping_week                    0.194935\n",
      "Order Item Profit Ratio          0.180687\n",
      "shipping_weekend                 0.166413\n",
      "order_dayofweek                  0.154737\n",
      "Benefit per order                0.142538\n",
      "Order Profit Per Order           0.142538\n",
      "Sales_lag_30                     0.126513\n",
      "precip                           0.113815\n",
      "order_weekend                    0.082490\n",
      "year                             0.078333\n",
      "humidity                         0.052751\n",
      "cloudcover                       0.037945\n",
      "tempmin                          0.000221\n",
      "windspeed                       -0.000971\n",
      "snow                            -0.004850\n",
      "temp                            -0.006338\n",
      "tempmax                         -0.024937\n",
      "temp_lag_1                      -0.033747\n",
      "temp_lag_7                      -0.040719\n",
      "temp_lag_30                     -0.047096\n",
      "solarradiation                  -0.058922\n",
      "Product Status                        NaN\n",
      "is_rain                               NaN\n",
      "is_snow                               NaN\n",
      "is_freezingrain                       NaN\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "Dropping 15 highly correlated features (>0.9, not target): {'order_month', 'tempmin', 'Order Item Id', 'Product Card Id', 'Order Item Total', 'Product Price', 'shipping_month', 'temp', 'Order Customer Id', 'Department Id', 'Order Profit Per Order', 'Product Category Id', 'shipping_week', 'Sales_lag_1', 'Order Item Cardprod Id'}\n",
      "\n",
      "Saved Step 1 feature-filtered dataset (with target): ./final_datasets/Feature_Selected_Step1_new.csv\n"
     ]
    }
   ],
   "source": [
    "# feature_selection_step1_correlation_fixed.py\n",
    "# Step 1: Correlation filtering for DataCo + Weather dataset (keeps Sales).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "INPUT_FILE = \"./final_datasets/DataCo_Weather_Lagged.csv\"  # Dataset with lags\n",
    "OUTPUT_FILE = \"./final_datasets/Feature_Selected_Step1_new.csv\"\n",
    "TARGET = \"Sales\"  \n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Use only Train/Validation (2015â€“2016) for feature selection\n",
    "df[\"date_only\"] = pd.to_datetime(df[\"date_only\"], errors='coerce')\n",
    "df_train = df[df[\"date_only\"].dt.year.isin([2015, 2016])].copy()\n",
    "\n",
    "# Select numeric features (exclude coords and date)\n",
    "numeric_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col not in [\"latitude\", \"longitude\"]]  # coords stay separate\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_train[numeric_cols].corr()\n",
    "\n",
    "# Show correlation with target\n",
    "print(\"\\n=== Correlation with Target (Sales) ===\")\n",
    "target_corr = corr_matrix[TARGET].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Drop redundant features (correlated with other features > 0.9, but never drop TARGET)\n",
    "threshold = 0.9\n",
    "to_drop = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            if colname != TARGET:  # Never drop Sales (target)\n",
    "                to_drop.add(colname)\n",
    "\n",
    "print(f\"\\nDropping {len(to_drop)} highly correlated features (>0.9, not target): {to_drop}\")\n",
    "\n",
    "# Keep selected features + target + coords + date\n",
    "selected_cols = [col for col in numeric_cols if col not in to_drop]\n",
    "\n",
    "# Always include Sales in the final output\n",
    "final_cols = [TARGET] + [col for col in selected_cols if col != TARGET] + [\"latitude\", \"longitude\", \"date_only\"]\n",
    "\n",
    "# Save the filtered dataset\n",
    "df_train[final_cols].to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved Step 1 feature-filtered dataset (with target): {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aefe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e04403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading correlation-filtered dataset...\n",
      "Training Random Forest for feature ranking...\n",
      "\n",
      "Saved ranked feature importance: ./final_datasets/Feature_Importance_Ranked.csv\n",
      "\n",
      "=== Top 20 Features ===\n",
      "                          Feature  Importance\n",
      "3              Sales per customer    0.991365\n",
      "9             Order Item Discount    0.004262\n",
      "13            Order Item Quantity    0.000697\n",
      "10       Order Item Discount Rate    0.000478\n",
      "4              Late_delivery_risk    0.000436\n",
      "5                     Category Id    0.000385\n",
      "20             shipping_dayofweek    0.000283\n",
      "8                        Order Id    0.000221\n",
      "11       Order Item Product Price    0.000209\n",
      "16                     order_week    0.000165\n",
      "21               shipping_weekend    0.000141\n",
      "26                      windspeed    0.000129\n",
      "17                order_dayofweek    0.000114\n",
      "0        Days for shipping (real)    0.000100\n",
      "6                     Customer Id    0.000094\n",
      "15                     order_hour    0.000091\n",
      "7                Customer Zipcode    0.000087\n",
      "23                       humidity    0.000081\n",
      "27                     cloudcover    0.000080\n",
      "1   Days for shipment (scheduled)    0.000073\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Rank features by importance using Random Forest (nonlinear).\n",
    "# Uses filtered dataset from Step 1 (correlation-filtered).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "INPUT_FILE = \"./final_datasets/Feature_Selected_Step1_new.csv\"  # Output from Step 1\n",
    "OUTPUT_FILE = \"./final_datasets/Feature_Importance_Ranked.csv\"\n",
    "TARGET = \"Sales\"\n",
    "TOP_N = 20  # How many features to keep (adjust based on results)\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading correlation-filtered dataset...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Ensure date is datetime\n",
    "df[\"date_only\"] = pd.to_datetime(df[\"date_only\"], errors='coerce')\n",
    "\n",
    "# Select features (exclude coords and date for training)\n",
    "features = [col for col in df.columns if col not in [\"date_only\", \"latitude\", \"longitude\", TARGET]]\n",
    "\n",
    "X = df[features]\n",
    "y = df[TARGET]\n",
    "\n",
    "# Train-test split (just for ranking stability)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"Training Random Forest for feature ranking...\")\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_ranking = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Save full ranking\n",
    "feature_ranking.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved ranked feature importance: {OUTPUT_FILE}\")\n",
    "\n",
    "# Print top N features\n",
    "print(f\"\\n=== Top {TOP_N} Features ===\")\n",
    "print(feature_ranking.head(TOP_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15724ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Step 1 dataset...\n",
      "\n",
      "Running RFE to select top 20 features...\n",
      "\n",
      "Selected Top 20 Features:\n",
      " - Days for shipping (real)\n",
      " - Sales per customer\n",
      " - Late_delivery_risk\n",
      " - Category Id\n",
      " - Customer Id\n",
      " - Customer Zipcode\n",
      " - Order Id\n",
      " - Order Item Discount\n",
      " - Order Item Discount Rate\n",
      " - Order Item Product Price\n",
      " - Order Item Quantity\n",
      " - order_hour\n",
      " - order_week\n",
      " - order_dayofweek\n",
      " - shipping_hour\n",
      " - shipping_dayofweek\n",
      " - shipping_weekend\n",
      " - humidity\n",
      " - windspeed\n",
      " - cloudcover\n",
      "\n",
      "Validation RMSE with top 20 features: 60.1250\n",
      "\n",
      "Saved Final Feature-Selected Train Dataset: ./final_datasets/Final_Selected_Features.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Final feature selection using Recursive Feature Elimination (RFE)\n",
    "# Selects top N features with Random Forest, evaluates RMSE.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "# === Config ===\n",
    "DATA_FILE = \"./final_datasets/Feature_Selected_Step1_new.csv\"  # Dataset after correlation filtering\n",
    "OUTPUT_FILE = \"./final_datasets/Final_Selected_Features.csv\"\n",
    "TARGET = \"Sales\"   # Target column\n",
    "TOP_N = 20         # How many features to keep (adjust as needed)\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading Step 1 dataset...\")\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Ensure date is datetime\n",
    "df[\"date_only\"] = pd.to_datetime(df[\"date_only\"], errors='coerce')\n",
    "\n",
    "# Filter to Train/Validation period (2015â€“2016 only)\n",
    "df_train = df[df[\"date_only\"].dt.year.isin([2015, 2016])].copy()\n",
    "\n",
    "# Identify feature columns (exclude target, coords, and date)\n",
    "features = [col for col in df_train.columns if col not in [\"date_only\", \"latitude\", \"longitude\", TARGET]]\n",
    "X = df_train[features]\n",
    "y = df_train[TARGET]\n",
    "\n",
    "# Train-validation split for model stability\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Recursive Feature Elimination (RFE)\n",
    "print(f\"\\nRunning RFE to select top {TOP_N} features...\")\n",
    "selector = RFE(rf, n_features_to_select=TOP_N, step=1)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = [f for f, keep in zip(features, selector.support_) if keep]\n",
    "print(f\"\\nSelected Top {TOP_N} Features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\" - {feat}\")\n",
    "\n",
    "# Evaluate model performance (RMSE) on validation data using selected features\n",
    "X_val_selected = X_val[selected_features]\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "y_pred = rf.predict(X_val_selected)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"\\nValidation RMSE with top {TOP_N} features: {rmse:.4f}\")\n",
    "\n",
    "# Save the final Train dataset (2015â€“2016) with selected features\n",
    "final_cols = [TARGET] + selected_features + [\"latitude\", \"longitude\", \"date_only\"]\n",
    "df_train[final_cols].to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved Final Feature-Selected Train Dataset: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb35e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"numpy<=2.2\" --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall shap numba -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"numpy<=2.2\" --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
